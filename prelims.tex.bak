Regardless of the temporal mining task, the first step of an algorithm is to transform,
or abstract, the raw data into a more concise representation, preserving as much of the
information contained in the original sequence as possible. Semiparametric temporal
clustering makes useful parametric assumptions for approximating temporal data and
regularizes sequences for input to a clustering step. The temporal abstractions, abstractions
of the raw time-series, function as input to a non-parametric clustering algorithm.




\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{fig/semipoverview.jpg}}
\caption{Historical locations and number of accepted papers for International
  Machine Learning Conferences (ICML 1993 -- ICML 2008) and
  International Workshops on Machine Learning (ML 1988 -- ML
  1992). At the time this figure was produced, the number of
  accepted papers for ICML 2008 was unknown and instead estimated.}
\label{icml-historical}
\end{center}
\vskip -0.2in
\end{figure}

Although existing data mining approaches have demonstrated their ability
to reveal unseen patterns and summarize data in meaningful ways, they have primarily
focused on static data sets. Few real-world data sets are by nature static, or are designed  to measure stationary phenomena; rather, they are evolving. However, the nature of
temporal data is challenging for existing data mining methods, and more traditional
statistical methods designed for working with longitudinal data such as life-history and
survival analysis.



///semiparametric clustering
Model-based methods to abstract temporal information provide a principled way to transform highly variable length sequences into a uniform length vector that approximates the whole sequence. The semi-parametric framework has been shown to outperform standard model-based clustering methods for time series data.  Working under the assumption that each time series was generated by an underlying Markovian process that can be modeled, the similarity among models serves as the basis for clustering.  It consists of two common algorithmic steps:

1) estimating the model parameters for each time series
2) a nonparametric clustering method that operates on the set of models instead of the raw time series data

provide useful parametric assumption for modeling temporal dynamics.  Problem semantics are defined in
a graphical model, and for each  and a nonparametric
method is used to cluster the temporal abstractions instead of operating on
the original data.  Working under the assumption that each time series was generated by an
underlying process that can be modeled, the similarity among models
serves as the basis for time series clustering.


Although extensive work exists to detect significant individual variation in the critical care environment,  We focus on improving exploratory analysis techniques for temporal EHR data using a probabilistic approach to model time series data sampled at arbitrate times, discovering clusters of clinically related patients, and visually communicating results.  Although substantial work has been conducted to model time series in the critical environment, techniques for longer-term chronic disease modeling are needed.

%that can be used to discover new knowledge that can be used to diagnose and manage chronic conditions, and impact health outcomes.


%challenges
This paper describes a semiparametric learning framework that uses continuous time dynamic Bayesian networks (CT-DBNs) to impose useful parametric assumptions for abstract raw temporal patient data and summarize it in a more manageable form, with nonparametric Bayesian clustering to reveal underlying group structure among clinically related patients.

%potential to chrinoc disease
 Many chronic illnesses can take years to develop and evolve at different rates in patients. However, the vast majority of clinical studies generalize disease dynamics based on only a few cross-sections of time. One reason is that historically, following a cohort of individuals entailed the design of customized measurement tools to monitor patients for a research study and explicit checkpoints for data collection. As electronic health record (EHR) databases grow in number, size and scale, they offer a rich, more accessible, pool of temporal data, but their secondary nature presents additional challenges. We examine the role of probabilistic machine learning methods to model temporal disease dynamics from arbitrarily sampled, noisy clinical data to reveal group structure and guide additional clinical insights.

Time provides critical context for many real-world reasoning tasks and temporal
clustering can provide insight into the nature of dynamic processes that are not well
understood. Although existing data mining approaches have demonstrated their ability
to reveal unseen patterns and summarize data in meaningful ways, they have primarily
focused on static data sets. Few real-world data sets are by nature static, or are designed
to measure stationary phenomena; rather, they are evolving.

However, the nature of
temporal data is challenging for existing data mining methods, and more traditional
statistical methods designed for working with longitudinal data such as life-history and
survival analysis.
What has been developed in the data mining and machine learning communities are
two main types of methods: feature based approaches and probabilistic graphical model
(PGM) based abstraction. There are many successful feature based temporal mining
algorithms, but they are task specific. Feature-based approaches extract information in
order to characterize the shapes that correspond with change along the duration of the
temporal trajectory. They don’t have a direct correspondence with the description of
the phenomena or underlying process more generally.

PGM based abstraction, specifically dynamic Bayesian networks (DBNs), more
easily yields an interpretation or explanation in that it models the data generating process.
Algorithmic components, such as clustering, can operate on these structures and
are not tightly coupled with the problem semantics, allowing for flexibility and reuse.

Also, the offer a principled way to represent variable length raw data as a uniform
length vector. However, there is a fundamental weakness of babbling DBNs to some
types of problems. DBNs require that continuous time is represented as a series of uniform
length units equal to the smalls time granularity in any observed sequence. When
data is missing or otherwise incomplete, information is still propagated throughout the
model for every time step. It has been shown that when missing data is not at random,
which is the case in medical data, it can result in significantly more EM steps to learn
the model parameters, and more importantly, lead to erroneous findings.

Lastly, the reasons above motivate our work but it is important to note the following.
Although unsupervised learning methods have many success stories, and likely more
to come, it’s important to note that these tools do not replace human experts. Instead,
methods for identifying latent structure without providing knowledge about their class
2




In the remainder of this paper, we describe our extensions to the semiparametric clustering framework.  We report results for two sets of experiments: (1) modeling


Time series analysis is the health and medical domain is an active research area.  Historically, following a cohort of individuals entailed the design of customized measurement tools to monitoring patients for a research study and explicit checkpoints for data collection.


The progression of time creates a continuous sequence, and specific measurements collected periodically allow scientists to study complex phenomena such as money markets or weather patterns.  Time series analysis is an important tool for scientific analyses, providing insight into the evolution of processes that may not be governed by linear trends.  Although many data collection methods follow a strict sequence of points, patient tracking in EHRs can reflect a variety of sampling methods including

For a continuous-time homogeneous Markov process with transition
intensity matrix

One specific case for which discretization of the temporal trajectory into regular intervals
has been known to contribute to error, is that of longitudinal data derived from
monitoring disease phenomena and is why there are fewer applications of discrete-time
Markov models in medicine~\cite{Jackson10}. SInce observations are typically documented only
during hospital or physician visits, resulting in irregular time intervals. Also, a patient’s
measurement sequence be short or can span over many years and the nature of
the observation scheme (e.g., fixed, random or self-selected) can be unclear.
Despite these challenges, health services researchers generally agree that electronic
health record (EHR) data provides many opportunities for new knowledge discovery,
and there is tremendous potential for value beyond meaningful use. The temporal
dimension of indicter data provides critical context for diagnosis and prognosis of many
patients suffering from chronic diseases.


dynamics that have direct relevance to important data analysis problems. That is, for
processes monitored at fixed intervals, the discretization of time into a vector of uniform
length fragments, is an appropriate modeling assumption. Although no one would
argue that time is discrete, when observations are collected in high-frequency settings,
or continually monitored at regular intervals it presents benefits. However, this is not appropriate in the case in data sources that evolve in continuous time, subject to variable
sampling schemes and incomplete.
